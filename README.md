# AI Coding Critics

Can LLMs like GPT-4 write code? It's well known that GPT-4 and other models make mistakes, even hallucinating information. Even so, it's become an incredible tool for developers, providing a new dimension to coding: fully intelligent help. But if it can help developers fix their coding errors, then can it correct its own mistakes?

This repo answers that question. It gives coding problems to GPT-4 to solve, then asks several questions about the code. If the code is correct, the AI Critic Agent will give a positive response. If the code is incorrect, the AI Critic Agent will give a negative response. If the code is correct, but the AI Critic Agent is wrong, the AI Fixer Agent will attempt to correct the code. Finally, the AI Tester Agent will ask the AI Critic Agent to solve the same problem again, and compare the results.

### A note on Nomenclature.

## AI Coder Agent

## AI Critic Agent

## AI Fixer Agent

## AI Tester Agent

## The Code

The code is primarily focused on reliably interacting with the OpenAI API. It handles a number of issues:

1. The API sometimes returns long runs of spaces and newlines. This is apparently generated by the
   GPT model, uncaught by the API. The problem is eventually terminated when the output reaches the
   requested maximum length. The API will return a `ChatChoice` with a `FinishReason` of `Length`.
   However, this is inefficient, especially as the requested response lengths increase. So this code
   demonstrates how to catch the terminate the runaway response early.
1. Request timeouts and other standard API errors are handled.

### Running the code

To run the code, you need to set the `OPENAI_API_KEY` environment variable to a valid OpenAi API key. View/create one [here](https://platform.openai.com/api-keys).

Note: The code is set up to run GPT-4, specifically `gpt-4-1106-preview`. If your API key corresponds to a different model, change the `MODEL` constant in `src/chatter_JSON.rs` . The list of available models is [here](https://platform.openai.com/docs/models/continuous-model-upgrades).

Export the API key in your shell, like:

```bash
$ export OPENAI_API_KEY=your_api_key
```

Protip: Use [direnv](https://direnv.net/) to set the environment variable for you as needed.

Now you can run the code:

```bash
$ cargo run
```

to try the first example problem, found in `problems/coding_problem1`. To try the other problems, or one in a file of your own, pass the filename:

```bash
$ cargo run -- problems/coding_problem3.txt
```

or

```bash
$ cargo run -- <your_filename>
```

### Problem format

The coding problems are formatted as plain text files. Lines beginning with `#` are ignored. The problem is sent directly to GPT-4. There is no need to add any additional prompting to instruct GPT about the problem or desired output. The code will provide a system prompt to instruct the model to generate the desired output format.

### Example Outputs
